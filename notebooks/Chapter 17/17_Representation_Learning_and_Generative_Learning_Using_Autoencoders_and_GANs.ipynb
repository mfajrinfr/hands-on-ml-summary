{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392c4fa9",
   "metadata": {},
   "source": [
    "# **Chapter 17: Representation Learning and Generative Learning Using Autoencoders and GANs**\n",
    "\n",
    "## **1. Pendahuluan**\n",
    "\n",
    "Bayangkan jika kita bisa belajar mengenali wajah seseorang tanpa pernah diberi tahu nama atau label apa pun. Atau, bayangkan jika komputer bisa \"bermimpi\" dan menciptakan gambar pemandangan yang belum pernah ada sebelumnya. Inilah dunia **Unsupervised Learning** dan **Generative Learning**.\n",
    "\n",
    "Dalam bab-bab sebelumnya, kita sebagian besar berfokus pada *Supervised Learning* (ada label target). Di bab ini, kita akan menjelajahi dua arsitektur Deep Learning yang bekerja tanpa label:\n",
    "1.  **Autoencoders:** Jaringan saraf yang belajar menyalin input ke output dengan cara yang efisien. Tujuannya adalah mempelajari representasi (coding) yang ringkas dari data.\n",
    "2.  **Generative Adversarial Networks (GANs):** Dua jaringan saraf yang saling bersaingâ€”satu mencoba memalsukan data, yang lain mencoba mendeteksi kepalsuan tersebut. Hasilnya adalah kemampuan untuk menghasilkan data baru yang sangat realistis.\n",
    "\n",
    "Mengapa ini penting?\n",
    "* **Dimensionality Reduction:** Mengompresi data tanpa kehilangan informasi vital.\n",
    "* **Feature Extraction:** Mempelajari fitur berguna untuk pre-training model supervised.\n",
    "* **Generative Models:** Menciptakan konten baru (gambar, musik, teks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810b876",
   "metadata": {},
   "source": [
    "## **2. Efficient Data Representations dengan Autoencoders**\n",
    "\n",
    "### **Konsep Dasar**\n",
    "Autoencoder adalah jaringan saraf yang dilatih untuk merekonstruksi inputnya sendiri.\n",
    "* **Encoder:** Mengubah input menjadi representasi laten (kode) yang lebih kecil.\n",
    "* **Decoder:** Mengubah kode kembali menjadi input asli.\n",
    "\n",
    "Kuncinya adalah **Bottleneck**: Kita membatasi ukuran kode (jumlah neuron di tengah) agar lebih kecil dari input. Ini memaksa jaringan untuk mempelajari pola-pola terpenting saja dan membuang *noise*.\n",
    "\n",
    "### **Linear Autoencoder (PCA)**\n",
    "Jika kita menggunakan fungsi aktivasi linear dan loss MSE, Autoencoder berperilaku persis seperti Principal Component Analysis (PCA).\n",
    "\n",
    "Mari kita coba dengan dataset **Fashion MNIST**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbeb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Mempersiapkan Dataset Fashion MNIST\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "\n",
    "# Flatten dataset untuk Dense Layer\n",
    "X_train_flat = X_train.reshape(-1, 28 * 28)\n",
    "X_valid_flat = X_valid.reshape(-1, 28 * 28)\n",
    "X_test_flat = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# Membangun Stacked Autoencoder Sederhana\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[784]),\n",
    "    keras.layers.Dense(30, activation=\"selu\")  # Bottleneck layer (Latent Space)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(784, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "autoencoder.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
    "\n",
    "# Melatih Model (Autoencoder belajar merekonstruksi inputnya sendiri: X -> X)\n",
    "history = autoencoder.fit(X_train_flat, X_train_flat, epochs=10, \n",
    "                          validation_data=(X_valid_flat, X_valid_flat), verbose=0)\n",
    "print(\"Training Stacked Autoencoder selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6130f",
   "metadata": {},
   "source": [
    "### **Visualisasi Rekonstruksi**\n",
    "Mari kita lihat seberapa baik Autoencoder mengompresi dan mengembalikan gambar baju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca445bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def show_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = model.predict(images.reshape(-1, 28 * 28))\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index]) # Gambar Asli\n",
    "        plt.title(\"Asli\")\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index].reshape(28, 28)) # Rekonstruksi\n",
    "        plt.title(\"Rekonstruksi\")\n",
    "    plt.show()\n",
    "\n",
    "show_reconstructions(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93e143",
   "metadata": {},
   "source": [
    "### **Denoising Autoencoders**\n",
    "Salah satu cara memaksa Autoencoder belajar fitur yang lebih robust adalah dengan menambahkan *noise* pada input, tetapi memintanya merekonstruksi gambar asli (bersih).\n",
    "* Ini memaksa model untuk memisahkan sinyal (fitur struktur gambar) dari noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8165fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan Gaussian Noise ke input\n",
    "gaussian_noise = keras.layers.GaussianNoise(0.2)\n",
    "\n",
    "denoising_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    gaussian_noise,\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\")\n",
    "])\n",
    "\n",
    "denoising_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "denoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\n",
    "denoising_ae.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "# Note: Input ada noise, Target adalah gambar bersih (X_train)\n",
    "# denoising_ae.fit(X_train, X_train, epochs=10, validation_data=(X_valid, X_valid))\n",
    "print(\"Arsitektur Denoising Autoencoder siap.\")\n",
    "denoising_ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9ddd3",
   "metadata": {},
   "source": [
    "## **3. Variational Autoencoders (VAE)**\n",
    "\n",
    "Autoencoder biasa menghasilkan representasi laten yang deterministik. VAE berbeda: ia adalah **Probabilistic Generative Model**.\n",
    "\n",
    "Alih-alih mempelajari satu vektor kode tetap, Encoder memprediksi **distribusi probabilitas** (Mean $\\mu$ dan Log-Variance $\\gamma$) dari mana kode akan disampling.\n",
    "\n",
    "**Komponen Utama:**\n",
    "1.  **Probabilistic Encoder:** Menghasilkan $\\mu$ dan $\\gamma$.\n",
    "2.  **Sampling:** Mengambil sampel $z$ dari distribusi Gaussian menggunakan *Reparameterization Trick*.\n",
    "3.  **Probabilistic Decoder:** Merekonstruksi gambar dari $z$.\n",
    "4.  **Loss Function:** Gabungan dari *Reconstruction Loss* (agar mirip input) dan *Latent Loss* (KL Divergence, agar distribusi laten mendekati Normal Gaussian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dea2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "codings_size = 10\n",
    "\n",
    "# Encoder\n",
    "inputs = keras.layers.Input(shape=[28, 28])\n",
    "z = keras.layers.Flatten()(inputs)\n",
    "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
    "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
    "codings_mean = keras.layers.Dense(codings_size)(z) # Mu\n",
    "codings_log_var = keras.layers.Dense(codings_size)(z) # Gamma\n",
    "codings = Sampling()([codings_mean, codings_log_var])\n",
    "variational_encoder = keras.models.Model(\n",
    "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
    "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
    "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
    "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "outputs = keras.layers.Reshape([28, 28])(x)\n",
    "variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
    "\n",
    "# VAE Model\n",
    "_, _, codings = variational_encoder(inputs)\n",
    "reconstructions = variational_decoder(codings)\n",
    "vae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
    "\n",
    "# Custom Loss (Reconstruction + KL Divergence)\n",
    "latent_loss = -0.5 * K.sum(\n",
    "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
    "    axis=-1)\n",
    "vae.add_loss(K.mean(latent_loss) / 784.0)\n",
    "vae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "print(\"Variational Autoencoder (VAE) siap dilatih untuk generative task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a966b",
   "metadata": {},
   "source": [
    "## **4. Generative Adversarial Networks (GANs)**\n",
    "\n",
    "Diusulkan oleh Ian Goodfellow pada 2014, GAN adalah salah satu ide paling cemerlang di AI modern.\n",
    "\n",
    "### **Konsep: The Adversarial Game**\n",
    "GAN terdiri dari dua jaringan yang bersaing (seperti polisi vs pemalsu uang):\n",
    "1.  **Generator:** Menerima *random noise* dan mencoba menghasilkan gambar palsu yang meyakinkan.\n",
    "2.  **Discriminator:** Menerima gambar (asli dan palsu) dan mencoba menebak mana yang asli.\n",
    "\n",
    "Tujuan Generator adalah menipu Discriminator. Tujuan Discriminator adalah tidak tertipu. Kompetisi ini mendorong keduanya menjadi semakin pintar hingga Generator menghasilkan data yang sangat realistis.\n",
    "\n",
    "### **Pelatihan GAN**\n",
    "Pelatihan GAN sangat sulit karena masalah **Nash Equilibrium** dan **Mode Collapse**. Kita harus melatih Discriminator satu langkah, lalu Generator satu langkah secara bergantian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f15944",
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 30\n",
    "\n",
    "# Generator: Noise -> Image\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "# Discriminator: Image -> Real/Fake (Binary Classification)\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "\n",
    "# Discriminator dilatih terpisah, jadi saat melatih GAN (Generator), bobot Discriminator dibekukan\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False \n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "print(\"Arsitektur Simple GAN berhasil didefinisikan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bcf587",
   "metadata": {},
   "source": [
    "### **Training Loop GAN**\n",
    "Berbeda dengan model biasa, kita tidak bisa hanya memanggil `.fit()`. Kita perlu *custom training loop*:\n",
    "1.  Latih Discriminator dengan batch campuran (gambar asli + gambar palsu dari Generator).\n",
    "2.  Latih Generator (lewat model `gan`) dengan memberikan label \"Asli\" pada gambar palsu (untuk menipu Discriminator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=1):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch in dataset:\n",
    "            # Fase 1: Latih Discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size) # 0=Fake, 1=Real\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            \n",
    "            # Fase 2: Latih Generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size) # Generator ingin Discriminator bilang ini \"1\" (Real)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        print(f\"Epoch {epoch+1} selesai.\")\n",
    "\n",
    "# Mempersiapkan dataset untuk training loop\n",
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "# train_gan(gan, dataset, batch_size, codings_size) # Komentar: Pelatihan butuh waktu\n",
    "print(\"Fungsi pelatihan GAN siap digunakan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4cda1e",
   "metadata": {},
   "source": [
    "## **5. Deep Convolutional GANs (DCGAN)**\n",
    "\n",
    "GAN sederhana dengan Dense layer tidak bekerja baik untuk gambar kompleks. **DCGAN** menggunakan lapisan konvolusi (Conv2D) dan *Transposed Convolution* (untuk upsampling di Generator).\n",
    "\n",
    "Panduan arsitektur DCGAN (dari paper asli Alec Radford):\n",
    "* Gunakan `Strided Convolutions` untuk downsampling (Discriminator) dan `Transposed Convolutions` untuk upsampling (Generator).\n",
    "* Gunakan `Batch Normalization` di kedua jaringan.\n",
    "* Hindari `Dense` layers sebisa mungkin.\n",
    "* Gunakan `ReLU` di Generator (kecuali output `Tanh`) dan `LeakyReLU` di Discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee70df2",
   "metadata": {},
   "source": [
    "## **6. Kesimpulan**\n",
    "\n",
    "Dalam Chapter 17 ini, kita telah menjelajahi sisi kreatif dari Deep Learning:\n",
    "1.  **Autoencoders:** Alat yang ampuh untuk reduksi dimensi, *denoising*, dan mempelajari representasi data yang efisien tanpa label.\n",
    "2.  **Variational Autoencoders (VAE):** Memperkenalkan konsep probabilistik ke dalam latent space, memungkinkan kita untuk men-generasi data baru dengan sampling.\n",
    "3.  **GANs:** Membuka pintu untuk generasi konten hiper-realistis melalui kompetisi adversarial antara Generator dan Discriminator.\n",
    "\n",
    "Pemahaman tentang representasi laten ini adalah kunci menuju konsep-konsep canggih seperti *Self-Supervised Learning* dan model generatif modern (seperti StyleGAN atau Stable Diffusion)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
